{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e5BB3G1hXL5"
      },
      "source": [
        "---\n",
        "Before you start exploring this notebook make sure that GPU support is enabled.\n",
        "To enable the GPU backend for your notebook, go to **Edit** â†’ **Notebook Settings** and set **Hardware accelerator** to **GPU**. \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUs4yMsgRSz"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D64rNsQCyL6Q"
      },
      "source": [
        "Install OpenAI Gym and dependencies to render the environments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqL6W_Gkgp9a"
      },
      "source": [
        "!apt update\n",
        "!apt install -y xvfb x11-utils python-opengl ffmpeg swig\n",
        "!pip install gymnasium==0.27.1 gymnasium[box2d] pyvirtualdisplay imageio-ffmpeg moviepy==1.0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ECmcPAOnhR4"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.distributions import Categorical\n",
        "from torch.utils.data.sampler import BatchSampler, SubsetRandomSampler\n",
        "from torchvision.transforms import Compose, ToTensor, Grayscale, ToPILImage\n",
        "\n",
        "# Auxiliary Python imports\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "from time import sleep, time, strftime\n",
        "\n",
        "# Environment import and set logger level to display error only\n",
        "import gymnasium as gym\n",
        "from gymnasium import logger as gymlogger\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "gymlogger.set_level(gym.logger.ERROR)\n",
        "\n",
        "# start virtual display\n",
        "from IPython.display import HTML, clear_output\n",
        "from IPython import display\n",
        "from pyvirtualdisplay import Display\n",
        "pydisplay = Display(visible=0, size=(640, 480))\n",
        "pydisplay.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyN5yRYY0v7u"
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to show video in a notebook cell\n",
        "\"\"\"\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    display.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De3CuyBLgXos"
      },
      "source": [
        "## Setup Google Drive mount to store your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpd2i1MumjP0"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.listdir('/content/drive/My Drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cx7q0Rn1v2s"
      },
      "source": [
        "# Action space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9ihClXhjvOT"
      },
      "source": [
        "# Action space (map from continuous actions for steering, throttle and break to 25 action combinations)\n",
        "action_mapping = [\n",
        "    (0, 0, 0),  # no action\n",
        "    (0, 0.5, 0),  # half throttle\n",
        "    (0, 1, 0),  # full trottle\n",
        "    (0, 0, 0.5),  # half break\n",
        "    (0, 0, 1),  # full break\n",
        "    # steering left with throttle/break control\n",
        "    (-0.5, 0, 0),  # half left\n",
        "    (-1, 0, 0),  # full left\n",
        "    (-0.5, 0.5, 0),  # half left\n",
        "    (-1, 0.5, 0),  # full left\n",
        "    (-0.5, 1, 0),  # half left\n",
        "    (-1, 1, 0),  # full left\n",
        "    (-0.5, 0, 0.5),  # half left\n",
        "    (-1, 0, 0.5),  # full left\n",
        "    (-0.5, 0, 1),  # half left\n",
        "    (-1, 0, 1),  # full left\n",
        "    # steering right with throttle/break control\n",
        "    (0.5, 0, 0),  # half right\n",
        "    (1, 0, 0),  # full right\n",
        "    (0.5, 0.5, 0),  # half right\n",
        "    (1, 0.5, 0),  # full right\n",
        "    (0.5, 1, 0),  # half right\n",
        "    (1, 1, 0),  # full right\n",
        "    (0.5, 0, 0.5),  # half right\n",
        "    (1, 0, 0.5),  # full right\n",
        "    (0.5, 0, 1),  # half right\n",
        "    (1, 0, 1)  # full right\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PelO4qdwuwK"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJeEIolVw0OQ"
      },
      "source": [
        "class Env():\n",
        "    \"\"\"\n",
        "    Environment wrapper for CarRacing \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,record_video=True):\n",
        "        self.record_video = record_video\n",
        "        self.gym_env = gym.make('CarRacing-v2', render_mode=\"rgb_array\")\n",
        "        self.env = self.wrap_env(self.gym_env)\n",
        "        self.action_space = self.env.action_space\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        self.env = self.wrap_env(self.gym_env)\n",
        "        self.rewards = []\n",
        "        img_rgb = self.env.reset()\n",
        "        return img_rgb\n",
        "\n",
        "    def step(self, action):\n",
        "        img_rgb, reward, terminated, truncated, _ = self.env.step(action)            \n",
        "        # accumulate reward\n",
        "        self.rewards.append(reward)            \n",
        "        # if no reward recently, end the episode\n",
        "        done = terminated or truncated\n",
        "        die = True if np.mean(self.rewards[-np.minimum(100, len(self.rewards)):]) <= -1 else False\n",
        "        if done or die:\n",
        "            self.close()\n",
        "\n",
        "        return img_rgb, np.sum(self.rewards[-1]), done, die\n",
        "\n",
        "    def render(self, *arg):\n",
        "        return self.env.render(*arg)\n",
        "\n",
        "    def close(self):\n",
        "        self.env.close()\n",
        "        \n",
        "    def wrap_env(self, env):\n",
        "        if self.record_video:\n",
        "            env = RecordVideo(env, './video', name_prefix=\"carracing-v2\", \n",
        "                              episode_trigger=lambda ep_id: True, \n",
        "                              disable_logger=True)\n",
        "        return env\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkjTFDi3y72N"
      },
      "source": [
        "### Run episode with random agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYqDb-EWw9QP"
      },
      "source": [
        "def run_episode(show_progress=True, record_video=True):\n",
        "    env = Env(record_video=record_video)\n",
        "    state = env.reset()\n",
        "    score = 0\n",
        "    done_or_die = False\n",
        "    ep=0\n",
        "    if show_progress:\n",
        "        progress = tqdm(desc=\"Score: 0\")\n",
        "    while not done_or_die:\n",
        "        action_idx = np.random.choice(len(action_mapping))\n",
        "        action = action_mapping[action_idx]\n",
        "        a_logp = 1/len(action_mapping) \n",
        "\n",
        "        state, reward, done, die = env.step(action)\n",
        "        score += reward\n",
        "        if ep > 500: # stop early\n",
        "           die = True\n",
        "        if show_progress:\n",
        "            progress.update()\n",
        "            progress.set_description(\"Score: {:.2f}\".format(score))\n",
        "        if done or die:\n",
        "            done_or_die = True\n",
        "        ep += 1\n",
        "    env.close()\n",
        "    if show_progress:\n",
        "        progress.close()    \n",
        "    if record_video:\n",
        "        show_video()\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0JaMOvxzBio"
      },
      "source": [
        "Let's see how the agent is doing in the real environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrqzgG-bzXws"
      },
      "source": [
        "run_episode(show_progress=True, record_video=True);"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}